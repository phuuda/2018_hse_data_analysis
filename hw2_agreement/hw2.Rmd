---
title: "hw1"
author: "Sofia Styrina"
date: "20 February 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### 1.1

```{r}
Sys.setlocale("LC_ALL","UTF-8")
library(tidyverse)

df <- read.csv("https://raw.githubusercontent.com/phuuda/2018_hse_data_analysis/master/hw2_agreement/hw2_1_zilo_class.csv", header = TRUE, sep=",")

df1 <- subset(df, select = c("stimulus_source", "stimulus"))

df2 <- aggregate(stimulus ~ stimulus_source, df1, function(x) length(unique(x)))

colnames(df2) <- c("stimulus_source","n")

df2 <- as_tibble(df2)
df2
```

### 1.2
```{r}
df %>%
  select(s_id, stimulus, translation_ru, stimulus_source, class) %>% 
  spread(key = s_id, value = class) ->
  zilo_classes_short

library(irr)
agree(zilo_classes_short[,-c(1:3)])
round(77.5*89/100)

```

### 1.3
```{r}
zilo_classes_2s <- zilo_classes_short[,c(10, 14)]
kappa2(zilo_classes_2s)
```

### 1.4
```{r}
kappam.fleiss(zilo_classes_short[,-c(1:3)])
```

### 1.5

* Для опроса было задействовано 89 stimulus-слов. 38 из них (42%) были native, и 51 (57%) - заимстованные

* Количество случаев полного согласия всех респондентов: 69 из 89 всех слов (77,5%), которые были классифицированы респондентами на типы r или b.

* Каппа Коэна для спикеров 7 и 11: 0.821

* Каппа Фляйса для всех спикеров: 0.868

* Reliability of agreement between speakers 7 & 11 is fairly close to the reliability between all speakers.

### 2.1
```{r}
verbs <- read.csv("https://github.com/phuuda/2018_hse_data_analysis/raw/master/hw2_agreement/hw2_2_verbs.csv", header = TRUE, sep=",")
subjects <-  as_tibble(unique(verbs$SubjectCode))
subjects
```

### 2.2
```{r}
verbs_data <- verbs[,c(1, 8, 11)]
f_all <- verbs_data[verbs_data$Gender == 'female', ]
f_nonce <- f_all[f_all$WordType == 'nonce', ]
f_stand <- f_all[f_all$WordType == 'standard', ]
f_margin <- f_all[f_all$WordType == 'marginal', ]

m_all <- verbs_data[verbs_data$Gender == 'male', ]
m_nonce <- m_all[m_all$WordType == 'nonce', ]
m_stand <- m_all[m_all$WordType == 'standard', ]
m_margin <- m_all[m_all$WordType == 'marginal', ]

gender_c <- c("female", "female", "female", "male", "male", "male")
w_type_c <- c("nonce", "standard", "marginal", "nonce", "standard", "marginal")
mean_c <- c(mean(f_nonce$GivenScore), mean(f_stand$GivenScore), mean(f_margin$GivenScore),
            mean(m_nonce$GivenScore), mean(m_stand$GivenScore), mean(m_margin$GivenScore))

all_means = as_tibble(data.frame(Gender=gender_c, WordType=w_type_c, mean=mean_c))
all_means
```

### 2.3
```{r}
verbs %>%
  select(SubjectCode, Stimulus, Prefix, WordType, GivenScore, CorpusFrequency) %>% 
  spread(key = SubjectCode, value = GivenScore) ->
  verb_scores

verb_scores_short <- na.omit(verb_scores)
agree(verb_scores_short[,-c(1:4)])
```

### 2.4
```{r}
kappam.fleiss(verb_scores_short[,-c(1:4)])
```

### 2.5
```{r}
icc(verb_scores_short[,-c(1:4)], model = "twoway", type = "agreement")
```

### 2.6
```{r}
scores_only <- verb_scores_short[,-c(1:4)]
v_score_cor <- cor(scores_only, method = "kendall")

cor_pairs <- data.frame(row=rownames(v_score_cor)[row(v_score_cor)[upper.tri(v_score_cor)]], 
                     col=colnames(v_score_cor)[col(v_score_cor)[upper.tri(v_score_cor)]], 
                     corr=v_score_cor[upper.tri(v_score_cor)])

ranker_list <- unique(cor_pairs$row)
maximums <- vector(mode="numeric", length=0)
minimums <- vector(mode="numeric", length=0)

for (r in ranker_list){
  cor_tmp <- cor_pairs[cor_pairs$row==r,]
  max_cor <- cor_tmp[which.max(cor_tmp$corr), ]
  min_cor <- cor_tmp[which.min(cor_tmp$corr), ]
  
  maximums <- c(maximums, max_cor[1, 3])
  minimums <- c(minimums, min_cor[1, 3])
}

min_max <- data.frame(ranker_list, maximums, minimums)
names(min_max) <- c('ranker', 'max_cor', 'min_cor')

min_max <- as_tibble(min_max)
min_max
```

